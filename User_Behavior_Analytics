project for User Behavior Analytics (UBA) using neural networks

User_Behavior_Analytics.py

# user_behavior_analytics.py

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

class UserBehaviorModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(UserBehaviorModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

def load_data(data_path):
    data = pd.read_csv(data_path)
    X = data.drop('label', axis=1).values
    y = data['label'].values
    return X, y

def preprocess_data(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, y_train, y_test

def train(model, X_train, y_train, epochs, learning_rate, batch_size):
    model.train()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=batch_size, shuffle=True)

    for epoch in range(epochs):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            if batch_idx % 100 == 0:
                print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                    epoch, batch_idx * len(data), len(train_loader.dataset),
                    100. * batch_idx / len(train_loader), loss.item()))

def evaluate(model, X_test, y_test):
    model.eval()
    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long()), batch_size=1024, shuffle=False)
    correct = 0
    total = 0

    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()

    accuracy = 100. * correct / total
    print('Accuracy of the network on the 10000 test images: {}%'.format(accuracy))

if __name__ == '__main__':
    data_path = 'path/to/user_behavior_data.csv'
    X, y = load_data(data_path)
    X_train, X_test, y_train, y_test = preprocess_data(X, y)
    model = UserBehaviorModel(X_train.shape[1], 128, 2)
    train(model, X_train, y_train, epochs=10, learning_rate=0.001, batch_size=32)
    evaluate(model, X_test, y_test)
